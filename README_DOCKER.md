# VoxCPM Docker éƒ¨ç½²æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ä¸€é”®å¯åŠ¨

```bash
./start.sh
```

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
1. âœ… æ£€æµ‹ NVIDIA GPU ç¯å¢ƒ
2. âœ… é€‰æ‹©æ˜¾å­˜å ç”¨æœ€å°‘çš„ GPU
3. âœ… æ£€æŸ¥ç«¯å£å¯ç”¨æ€§
4. âœ… å¯åŠ¨ Docker å®¹å™¨

### è®¿é—®æœåŠ¡

å¯åŠ¨åå¯é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¿é—®ï¼š

- **UI ç•Œé¢**: http://0.0.0.0:7861
- **API æ–‡æ¡£**: http://0.0.0.0:7861/apidocs
- **MCP æœåŠ¡**: ä½¿ç”¨ `mcp_client.json` é…ç½®

## ğŸ“¦ ä¸‰ç§è®¿é—®æ¨¡å¼

### 1. UI ç•Œé¢æ¨¡å¼

è®¿é—® http://0.0.0.0:7861 ä½¿ç”¨ Web ç•Œé¢ï¼š

**åŠŸèƒ½ï¼š**
- ğŸ¤ **è¯­éŸ³åˆæˆ**ï¼šè¾“å…¥æ–‡æœ¬ç”Ÿæˆè¯­éŸ³
- ğŸ­ **å£°éŸ³å…‹éš†**ï¼šä¸Šä¼ å‚è€ƒéŸ³é¢‘å…‹éš†å£°éŸ³
- âš™ï¸ **å‚æ•°è°ƒèŠ‚**ï¼šè°ƒæ•´ CFGã€æ¨ç†æ­¥æ•°ç­‰
- ğŸ–¥ï¸ **GPU ç›‘æ§**ï¼šå®æ—¶æŸ¥çœ‹ GPU çŠ¶æ€

### 2. API æ¨¡å¼

#### å¥åº·æ£€æŸ¥
```bash
curl http://localhost:7861/health
```

#### æ–‡æœ¬è½¬è¯­éŸ³
```bash
curl -X POST http://localhost:7861/api/tts \
  -F "text=Hello, this is VoxCPM" \
  -F "cfg_value=2.0" \
  -F "inference_timesteps=10" \
  --output output.wav
```

#### å£°éŸ³å…‹éš†
```bash
curl -X POST http://localhost:7861/api/tts \
  -F "text=Cloned voice speaking" \
  -F "prompt_audio=@reference.wav" \
  -F "prompt_text=Reference transcript" \
  --output cloned.wav
```

#### GPU çŠ¶æ€
```bash
curl http://localhost:7861/api/gpu/status
```

#### å¸è½½æ¨¡å‹
```bash
curl -X POST http://localhost:7861/api/gpu/offload
```

### 3. MCP æ¨¡å¼

è¯¦è§ [MCP_GUIDE.md](MCP_GUIDE.md)

**é…ç½® MCP å®¢æˆ·ç«¯ï¼š**
```json
{
  "mcpServers": {
    "voxcpm": {
      "command": "python3",
      "args": ["/home/neo/upload/VoxCPM/mcp_server.py"],
      "env": {
        "GPU_IDLE_TIMEOUT": "600"
      }
    }
  }
}
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python
# æ–‡æœ¬è½¬è¯­éŸ³
result = await mcp_client.call_tool(
    "text_to_speech",
    {"text": "Hello from MCP"}
)

# å£°éŸ³å…‹éš†
result = await mcp_client.call_tool(
    "voice_cloning",
    {
        "text": "Cloned voice",
        "reference_audio": "/path/to/ref.wav"
    }
)
```

## âš™ï¸ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡ (.env)

```bash
PORT=7861                    # æœåŠ¡ç«¯å£
GPU_IDLE_TIMEOUT=60         # GPU ç©ºé—²è¶…æ—¶ï¼ˆç§’ï¼‰
NVIDIA_VISIBLE_DEVICES=0    # GPU ID
HF_REPO_ID=openbmb/VoxCPM1.5  # æ¨¡å‹ ID
```

### å‚æ•°è¯´æ˜

| å‚æ•° | èŒƒå›´ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| cfg_value | 0.5-5.0 | 2.0 | å¼•å¯¼å¼ºåº¦ï¼Œè¶Šé«˜è¶Šè´´è¿‘æç¤º |
| inference_timesteps | 5-20 | 10 | æ¨ç†æ­¥æ•°ï¼Œè¶Šé«˜è´¨é‡è¶Šå¥½ä½†è¶Šæ…¢ |
| normalize | bool | false | æ–‡æœ¬è§„èŒƒåŒ– |
| denoise | bool | false | éŸ³é¢‘é™å™ª |

## ğŸ› ï¸ ç®¡ç†å‘½ä»¤

### æŸ¥çœ‹æ—¥å¿—
```bash
docker-compose logs -f
```

### åœæ­¢æœåŠ¡
```bash
docker-compose down
```

### é‡å¯æœåŠ¡
```bash
docker-compose restart
```

### é‡æ–°æ„å»º
```bash
docker-compose up -d --build
```

### è¿›å…¥å®¹å™¨
```bash
docker exec -it voxcpm-service bash
```

## ğŸ“Š GPU ç®¡ç†

### è‡ªåŠ¨ç®¡ç†

æœåŠ¡å†…ç½® GPU ç®¡ç†å™¨ï¼Œä¼šè‡ªåŠ¨ï¼š
- âœ… ç©ºé—² 60 ç§’åè‡ªåŠ¨å¸è½½æ¨¡å‹
- âœ… éœ€è¦æ—¶è‡ªåŠ¨åŠ è½½æ¨¡å‹
- âœ… é‡Šæ”¾ GPU æ˜¾å­˜

### æ‰‹åŠ¨ç®¡ç†

**é€šè¿‡ APIï¼š**
```bash
# æŸ¥çœ‹çŠ¶æ€
curl http://localhost:7861/api/gpu/status

# å¼ºåˆ¶å¸è½½
curl -X POST http://localhost:7861/api/gpu/offload
```

**é€šè¿‡ UIï¼š**
- è®¿é—® "GPU Status" æ ‡ç­¾é¡µ
- ç‚¹å‡» "Offload Model" æŒ‰é’®

**é€šè¿‡ MCPï¼š**
```python
await mcp_client.call_tool("offload_model", {})
```

## ğŸ”§ æ•…éšœæ’é™¤

### ç«¯å£è¢«å ç”¨

ä¿®æ”¹ `.env` ä¸­çš„ `PORT` å€¼ï¼š
```bash
PORT=7862
```

### GPU å†…å­˜ä¸è¶³

1. é™ä½ `inference_timesteps`
2. æ‰‹åŠ¨å¸è½½æ¨¡å‹
3. å¢åŠ  `GPU_IDLE_TIMEOUT` ä½¿æ¨¡å‹æ›´å¿«å¸è½½

### æ¨¡å‹ä¸‹è½½æ…¢

é¦–æ¬¡å¯åŠ¨éœ€è¦ä¸‹è½½æ¨¡å‹ï¼ˆçº¦ 3GBï¼‰ï¼Œå¯ä»¥ï¼š
1. ä½¿ç”¨å›½å†…é•œåƒæº
2. é¢„å…ˆä¸‹è½½æ¨¡å‹åˆ° `./models` ç›®å½•

### å®¹å™¨æ— æ³•å¯åŠ¨

æ£€æŸ¥ nvidia-dockerï¼š
```bash
nvidia-smi
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### æ¨èé…ç½®

| åœºæ™¯ | cfg_value | inference_timesteps | è¯´æ˜ |
|------|-----------|---------------------|------|
| å¿«é€Ÿé¢„è§ˆ | 1.5 | 5 | æœ€å¿«ï¼Œè´¨é‡è¾ƒä½ |
| å¹³è¡¡æ¨¡å¼ | 2.0 | 10 | æ¨èï¼Œé€Ÿåº¦ä¸è´¨é‡å¹³è¡¡ |
| é«˜è´¨é‡ | 2.5 | 15 | æœ€ä½³è´¨é‡ï¼Œè¾ƒæ…¢ |

### RTF (Real-Time Factor)

- RTX 4090: ~0.15
- RTX 3090: ~0.25
- RTX 3080: ~0.30

## ğŸ”’ å®‰å…¨å»ºè®®

1. **ç”Ÿäº§ç¯å¢ƒ**ï¼šä¿®æ”¹ç«¯å£ç»‘å®šä» `0.0.0.0` åˆ° `127.0.0.1`
2. **API è®¤è¯**ï¼šæ·»åŠ  API Key éªŒè¯
3. **æ–‡ä»¶ä¸Šä¼ **ï¼šé™åˆ¶ä¸Šä¼ æ–‡ä»¶å¤§å°å’Œç±»å‹
4. **é€Ÿç‡é™åˆ¶**ï¼šæ·»åŠ è¯·æ±‚é¢‘ç‡é™åˆ¶

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.0.0 (2025-12-12)
- âœ… åˆå§‹ Docker åŒ–ç‰ˆæœ¬
- âœ… æ”¯æŒ UI + API + MCP ä¸‰ç§æ¨¡å¼
- âœ… è‡ªåŠ¨ GPU ç®¡ç†
- âœ… å¤šè¯­è¨€æ”¯æŒ

## ğŸ†˜ è·å–å¸®åŠ©

- GitHub Issues: https://github.com/OpenBMB/VoxCPM/issues
- æŠ€æœ¯æ–‡æ¡£: [README.md](README.md)
- MCP æŒ‡å—: [MCP_GUIDE.md](MCP_GUIDE.md)
