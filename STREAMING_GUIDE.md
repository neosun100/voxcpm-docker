# ğŸŒŠ æµå¼éŸ³é¢‘è¾“å‡ºä¼˜åŒ–æŒ‡å—

> æœ¬æ–‡æ¡£è®°å½•äº† VoxCPM é¡¹ç›®åœ¨å®ç°æµå¼éŸ³é¢‘è¾“å‡ºè¿‡ç¨‹ä¸­é‡åˆ°çš„é—®é¢˜ã€è§£å†³æ–¹æ¡ˆå’Œä¼˜åŒ–ç»éªŒï¼Œå¯ä½œä¸ºå…¶ä»–é¡¹ç›®å®ç°æµå¼è¾“å‡ºçš„å‚è€ƒã€‚

## ğŸ“‹ ç›®å½•

1. [æµå¼è¾“å‡ºæ¶æ„](#æµå¼è¾“å‡ºæ¶æ„)
2. [éŸ³é¢‘æ ¼å¼é€‰æ‹©](#éŸ³é¢‘æ ¼å¼é€‰æ‹©)
3. [åç«¯æµå¼å®ç°](#åç«¯æµå¼å®ç°)
4. [å‰ç«¯æµå¼æ’­æ”¾](#å‰ç«¯æµå¼æ’­æ”¾)
5. [éŸ³é¢‘è´¨é‡é—®é¢˜ä¸è§£å†³](#éŸ³é¢‘è´¨é‡é—®é¢˜ä¸è§£å†³)
6. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
7. [ç»éªŒæ€»ç»“](#ç»éªŒæ€»ç»“)

---

## æµå¼è¾“å‡ºæ¶æ„

### æ•´ä½“æµç¨‹

```
[TTS æ¨¡å‹] â†’ [åç«¯ chunk ç”Ÿæˆ] â†’ [HTTP æµå¼å“åº”] â†’ [å‰ç«¯æ¥æ”¶] â†’ [Web Audio API æ’­æ”¾]
```

### å…³é”®å†³ç­–ç‚¹

| å†³ç­– | é€‰æ‹© | åŸå›  |
|------|------|------|
| ä¼ è¾“æ ¼å¼ | PCM (s16le) | æ— éœ€å¤´ä¿¡æ¯ï¼Œæ”¯æŒçœŸæ­£çš„æµå¼ |
| é‡‡æ ·ç‡ | 44100 Hz | é«˜è´¨é‡ï¼Œå…¼å®¹æ€§å¥½ |
| ä½æ·±åº¦ | 16-bit | å¹³è¡¡è´¨é‡å’Œå¸¦å®½ |
| å£°é“ | å•å£°é“ | TTS ä¸éœ€è¦ç«‹ä½“å£° |

---

## éŸ³é¢‘æ ¼å¼é€‰æ‹©

### WAV vs PCM çš„å…³é”®åŒºåˆ«

#### WAV æ ¼å¼çš„é—®é¢˜

WAV æ–‡ä»¶å¤´åŒ…å« `data` chunk çš„å¤§å°å­—æ®µï¼Œ**å¿…é¡»åœ¨å†™å…¥å‰çŸ¥é“æ€»å¤§å°**ï¼š

```
WAV æ–‡ä»¶ç»“æ„:
â”œâ”€â”€ RIFF header (4 bytes): "RIFF"
â”œâ”€â”€ File size (4 bytes): æ€»å¤§å° - 8
â”œâ”€â”€ WAVE header (4 bytes): "WAVE"
â”œâ”€â”€ fmt chunk (24 bytes): æ ¼å¼ä¿¡æ¯
â””â”€â”€ data chunk
    â”œâ”€â”€ "data" (4 bytes)
    â”œâ”€â”€ Data size (4 bytes): âš ï¸ å¿…é¡»é¢„å…ˆçŸ¥é“ï¼
    â””â”€â”€ Audio data...
```

**é—®é¢˜**ï¼šæµå¼ç”Ÿæˆæ—¶æ— æ³•é¢„çŸ¥æ€»å¤§å°ï¼Œå¯¼è‡´ï¼š
1. æ¯ä¸ª chunk å•ç‹¬å†™ WAV å¤´ â†’ å¤´ä¿¡æ¯å£°æ˜çš„å¤§å°ä¸å®é™…ä¸ç¬¦
2. æ’­æ”¾å™¨åªæ’­æ”¾å¤´ä¿¡æ¯å£°æ˜çš„é•¿åº¦ï¼Œåé¢çš„æ•°æ®è¢«æˆªæ–­

#### PCM æ ¼å¼çš„ä¼˜åŠ¿

PCM æ˜¯çº¯éŸ³é¢‘æ•°æ®ï¼Œ**æ— ä»»ä½•å¤´ä¿¡æ¯**ï¼š
- å¯ä»¥ç›´æ¥æ‹¼æ¥å¤šä¸ª chunk
- æ”¯æŒçœŸæ­£çš„è¾¹ç”Ÿæˆè¾¹ä¼ è¾“
- é¦–å­—èŠ‚å»¶è¿Ÿæä½ï¼ˆ~0.001sï¼‰

### æ ¼å¼é€‰æ‹©å»ºè®®

| åœºæ™¯ | æ¨èæ ¼å¼ | åŸå›  |
|------|----------|------|
| æµå¼æ’­æ”¾ | PCM | æ— å¤´ä¿¡æ¯ï¼ŒçœŸæ­£æµå¼ |
| æ–‡ä»¶ä¿å­˜ | WAV | å…¼å®¹æ€§å¥½ï¼Œå¯ç›´æ¥æ’­æ”¾ |
| ç½‘ç»œä¼ è¾“ | MP3/Opus | å‹ç¼©ç‡é«˜ï¼ŒèŠ‚çœå¸¦å®½ |

---

## åç«¯æµå¼å®ç°

### Python FastAPI å®ç°

```python
from fastapi import APIRouter
from fastapi.responses import StreamingResponse
import numpy as np

@router.post("/v1/audio/speech")
async def create_speech(request: SpeechRequest):
    def audio_stream():
        # PCM æ ¼å¼ï¼šçœŸæ­£çš„æµå¼è¾“å‡º
        if request.response_format == "pcm":
            is_first_chunk = True
            dc_offset = 0.0
            alpha = 0.001  # DC offset æ»‘åŠ¨å¹³å‡ç³»æ•°
            
            for wav_chunk in model.generate_streaming(...):
                # 1. å»é™¤ DC offsetï¼ˆæ»‘åŠ¨å¹³å‡ï¼‰
                chunk_mean = np.mean(wav_chunk)
                dc_offset = dc_offset * (1 - alpha) + chunk_mean * alpha
                wav_chunk = wav_chunk - dc_offset
                
                # 2. ç¬¬ä¸€ä¸ª chunk åº”ç”¨æ·¡å…¥æ•ˆæœ
                if is_first_chunk:
                    fade_len = min(2048, len(wav_chunk))
                    fade = np.linspace(0, 1, fade_len)
                    wav_chunk[:fade_len] *= fade
                    is_first_chunk = False
                
                # 3. è½¬æ¢ä¸º int16 PCM
                pcm_data = (wav_chunk * 32767).astype(np.int16)
                yield pcm_data.tobytes()
        
        # WAV æ ¼å¼ï¼šå¿…é¡»æ”¶é›†æ‰€æœ‰æ•°æ®åå†è¾“å‡º
        else:
            all_chunks = []
            for wav_chunk in model.generate_streaming(...):
                all_chunks.append(wav_chunk)
            
            full_audio = np.concatenate(all_chunks)
            
            # å†™å…¥å®Œæ•´çš„ WAV æ–‡ä»¶
            buffer = io.BytesIO()
            sf.write(buffer, full_audio, sample_rate, format='WAV', subtype='PCM_16')
            buffer.seek(0)
            yield buffer.read()
    
    return StreamingResponse(audio_stream(), media_type="audio/pcm")
```

### å…³é”®ç‚¹

1. **PCM æ ¼å¼æ‰èƒ½çœŸæ­£æµå¼**ï¼šWAV éœ€è¦å®Œæ•´æ•°æ®æ‰èƒ½å†™æ­£ç¡®çš„å¤´
2. **DC offset å¤„ç†**ï¼šä½¿ç”¨æ»‘åŠ¨å¹³å‡è€Œéæ¯ä¸ª chunk å•ç‹¬å¤„ç†
3. **æ·¡å…¥æ•ˆæœ**ï¼šåªå¯¹ç¬¬ä¸€ä¸ª chunk åº”ç”¨ï¼Œé¿å…å¼€å¤´çˆ†éŸ³

---

## å‰ç«¯æµå¼æ’­æ”¾

### Web Audio API å®ç°

```javascript
const SAMPLE_RATE = 44100;
const MIN_BUFFER_SIZE = 22050;  // 500ms ç¼“å†²
const FADE_SAMPLES = 2048;      // æ·¡å…¥é‡‡æ ·æ•°

let audioContext = null;
let activeSources = [];
let nextPlayTime = 0;

// åœæ­¢æ‰€æœ‰æ’­æ”¾
function stopAllAudio() {
    activeSources.forEach(s => { try { s.stop(); } catch(e) {} });
    activeSources = [];
}

// æ·¡å…¥æ•ˆæœ
function applyFadeIn(arr) {
    const len = Math.min(FADE_SAMPLES, arr.length);
    for (let i = 0; i < len; i++) arr[i] *= i / len;
}

async function playStreaming(url, text) {
    // åˆå§‹åŒ– AudioContext
    if (!audioContext) {
        audioContext = new AudioContext({ sampleRate: SAMPLE_RATE });
    }
    if (audioContext.state === 'suspended') {
        await audioContext.resume();
    }
    
    // åœæ­¢ä¹‹å‰çš„æ’­æ”¾
    stopAllAudio();
    
    // åˆå§‹åŒ–æ’­æ”¾æ—¶é—´ï¼ˆç•™å‡ºç¼“å†²ï¼‰
    nextPlayTime = audioContext.currentTime + 0.15;
    
    let pendingBytes = new Uint8Array(0);
    let samples = [];
    let isFirstChunk = true;
    
    // æ’­æ”¾ç´¯ç§¯çš„é‡‡æ ·
    function playBuffer() {
        if (samples.length === 0) return;
        
        const float32Array = new Float32Array(samples);
        
        // ç¬¬ä¸€ä¸ªå—åº”ç”¨æ·¡å…¥
        if (isFirstChunk) {
            applyFadeIn(float32Array);
            isFirstChunk = false;
        }
        
        // åˆ›å»ºéŸ³é¢‘ç¼“å†²åŒº
        const audioBuffer = audioContext.createBuffer(1, float32Array.length, SAMPLE_RATE);
        audioBuffer.getChannelData(0).set(float32Array);
        
        // åˆ›å»ºéŸ³é¢‘æº
        const source = audioContext.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(audioContext.destination);
        
        // è·Ÿè¸ªéŸ³é¢‘æº
        activeSources.push(source);
        source.onended = () => {
            const idx = activeSources.indexOf(source);
            if (idx > -1) activeSources.splice(idx, 1);
        };
        
        // é˜²æ­¢æ’­æ”¾æ—¶é—´è½åå¯¼è‡´é‡å 
        if (nextPlayTime < audioContext.currentTime - 0.1) {
            console.warn('Buffer underrun, resetting playback time');
            nextPlayTime = audioContext.currentTime + 0.05;
        }
        
        // è°ƒåº¦æ’­æ”¾
        source.start(nextPlayTime);
        nextPlayTime += audioBuffer.duration;
        
        samples = [];
    }
    
    // è·å–æµå¼å“åº”
    const response = await fetch(url, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
            model: 'tts-1',
            input: text,
            voice: 'alloy',
            response_format: 'pcm'
        })
    });
    
    const reader = response.body.getReader();
    
    while (true) {
        const { done, value } = await reader.read();
        if (done) {
            playBuffer();  // æ’­æ”¾å‰©ä½™æ•°æ®
            break;
        }
        
        // åˆå¹¶å¾…å¤„ç†å­—èŠ‚
        const combined = new Uint8Array(pendingBytes.length + value.length);
        combined.set(pendingBytes);
        combined.set(value, pendingBytes.length);
        
        // âš ï¸ å…³é”®ï¼šç¡®ä¿å­—èŠ‚æ•°æ˜¯å¶æ•°ï¼ˆInt16 = 2 bytesï¼‰
        const validLength = Math.floor(combined.length / 2) * 2;
        const validData = combined.slice(0, validLength);
        pendingBytes = combined.slice(validLength);
        
        // è½¬æ¢ PCM æ•°æ®
        const int16Array = new Int16Array(validData.buffer, validData.byteOffset, validData.length / 2);
        for (let i = 0; i < int16Array.length; i++) {
            samples.push(int16Array[i] / 32768);
        }
        
        // ç´¯ç§¯è¶³å¤Ÿæ•°æ®åæ’­æ”¾
        if (samples.length >= MIN_BUFFER_SIZE) {
            playBuffer();
        }
    }
}
```

### å…³é”®ç‚¹

1. **å­—èŠ‚å¯¹é½**ï¼šInt16 æ˜¯ 2 å­—èŠ‚ï¼Œç½‘ç»œåŒ…å¯èƒ½åœ¨å¥‡æ•°ä½ç½®åˆ‡åˆ†
2. **ç¼“å†²ç­–ç•¥**ï¼šç´¯ç§¯ 500ms æ•°æ®åå†æ’­æ”¾ï¼Œå‡å°‘ buffer åˆ‡æ¢
3. **æ—¶é—´åŒæ­¥**ï¼šæ£€æµ‹ buffer underrunï¼Œé‡ç½®æ’­æ”¾æ—¶é—´
4. **åœæ­¢æœºåˆ¶**ï¼šæ–°æ’­æ”¾å‰åœæ­¢ä¹‹å‰çš„éŸ³é¢‘ï¼Œé˜²æ­¢é‡å 

---

## éŸ³é¢‘è´¨é‡é—®é¢˜ä¸è§£å†³

### é—®é¢˜ 1ï¼šå¼€å¤´çˆ†éŸ³ï¼ˆPop/Clickï¼‰

**ç°è±¡**ï¼šéŸ³é¢‘å¼€å§‹æ—¶æœ‰æ˜æ˜¾çš„"å•ª"å£°

**åŸå› **ï¼š
1. éŸ³é¢‘ä»é™éŸ³ï¼ˆ0ï¼‰çªç„¶è·³åˆ°æœ‰å£°éŸ³çš„é‡‡æ ·å€¼
2. DC offset å¯¼è‡´åŸºå‡†çº¿ä¸åœ¨ 0

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# åç«¯ï¼šæ·¡å…¥æ•ˆæœ
if is_first_chunk:
    fade_len = min(2048, len(wav_chunk))  # ~46ms @ 44.1kHz
    fade = np.linspace(0, 1, fade_len)
    wav_chunk[:fade_len] *= fade
    is_first_chunk = False
```

```javascript
// å‰ç«¯ï¼šæ·¡å…¥æ•ˆæœ
function applyFadeIn(arr) {
    const fadeLen = Math.min(2048, arr.length);
    for (let i = 0; i < fadeLen; i++) {
        arr[i] *= i / fadeLen;
    }
}
```

### é—®é¢˜ 2ï¼šDC Offsetï¼ˆç›´æµåç§»ï¼‰

**ç°è±¡**ï¼šéŸ³é¢‘é‡‡æ ·å€¼æ•´ä½“åç¦» 0ï¼Œå¯¼è‡´æ’­æ”¾æ—¶æœ‰åº•å™ª

**åŸå› **ï¼šTTS æ¨¡å‹ç”Ÿæˆçš„éŸ³é¢‘æœ¬èº«å¸¦æœ‰ DC åç§»

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# åç«¯ï¼šæ»‘åŠ¨å¹³å‡å»é™¤ DC offset
dc_offset = 0.0
alpha = 0.001  # æ›´æ–°ç³»æ•°

for wav_chunk in model.generate_streaming(...):
    chunk_mean = np.mean(wav_chunk)
    dc_offset = dc_offset * (1 - alpha) + chunk_mean * alpha
    wav_chunk = wav_chunk - dc_offset
```

**æ³¨æ„**ï¼šä¸è¦å¯¹æ¯ä¸ª chunk å•ç‹¬å»é™¤ DC offsetï¼ˆå‡å»å„è‡ªçš„ meanï¼‰ï¼Œè¿™ä¼šå¯¼è‡´ chunk ä¹‹é—´åŸºå‡†çº¿ä¸ä¸€è‡´ï¼Œäº§ç”Ÿæ–°çš„æ‚éŸ³ã€‚

### é—®é¢˜ 3ï¼šå­—èŠ‚å¯¹é½é—®é¢˜

**ç°è±¡**ï¼šæ’­æ”¾ä¸­é—´å‡ºç°æ‚éŸ³æˆ–å™ªå£°

**åŸå› **ï¼šInt16 é‡‡æ ·æ˜¯ 2 å­—èŠ‚ï¼Œç½‘ç»œä¼ è¾“å¯èƒ½åœ¨å¥‡æ•°ä½ç½®åˆ‡åˆ†æ•°æ®åŒ…

**è§£å†³æ–¹æ¡ˆ**ï¼š

```javascript
// ç¡®ä¿å­—èŠ‚æ•°æ˜¯å¶æ•°
const validLength = Math.floor(combined.length / 2) * 2;
const validData = combined.slice(0, validLength);
pendingBytes = combined.slice(validLength);  // ä¿ç•™å¤šä½™çš„å­—èŠ‚
```

### é—®é¢˜ 4ï¼šéŸ³é¢‘é‡å ï¼ˆä¸¤ä¸ªå£°éŸ³ï¼‰

**ç°è±¡**ï¼šå¬åˆ°ä¸¤ä¸ªå£°éŸ³åŒæ—¶æ’­æ”¾

**åŸå› **ï¼š
1. å¤šæ¬¡ç‚¹å‡»æ’­æ”¾ï¼Œä¹‹å‰çš„éŸ³é¢‘è¿˜åœ¨æ’­æ”¾
2. Buffer è°ƒåº¦æ—¶é—´è®¡ç®—é”™è¯¯ï¼Œå¤šä¸ª buffer åŒæ—¶å¼€å§‹

**è§£å†³æ–¹æ¡ˆ**ï¼š

```javascript
// 1. æ’­æ”¾å‰åœæ­¢ä¹‹å‰çš„éŸ³é¢‘
function stopAllAudio() {
    activeSources.forEach(s => { try { s.stop(); } catch(e) {} });
    activeSources = [];
}

// 2. æ£€æµ‹ buffer underrunï¼Œé‡ç½®æ—¶é—´è€Œéé‡å 
if (nextPlayTime < audioContext.currentTime - 0.1) {
    nextPlayTime = audioContext.currentTime + 0.05;
}
```

### é—®é¢˜ 5ï¼šWAV å¤´å¤§å°ä¸åŒ¹é…

**ç°è±¡**ï¼šWAV æ–‡ä»¶åªæ’­æ”¾ä¸€å°éƒ¨åˆ†ï¼Œæˆ–æ’­æ”¾å™¨æ˜¾ç¤ºé”™è¯¯æ—¶é•¿

**åŸå› **ï¼šæµå¼è¾“å‡ºæ—¶æ¯ä¸ª chunk å•ç‹¬å†™ WAV å¤´ï¼Œå¤´ä¸­å£°æ˜çš„å¤§å°åªæ˜¯è¯¥ chunk çš„å¤§å°

**è§£å†³æ–¹æ¡ˆ**ï¼šWAV æ ¼å¼å¿…é¡»æ”¶é›†æ‰€æœ‰æ•°æ®åä¸€æ¬¡æ€§å†™å…¥

```python
# WAV æ ¼å¼ï¼šæ”¶é›†æ‰€æœ‰ chunk åå†å†™
all_chunks = []
for wav_chunk in model.generate_streaming(...):
    all_chunks.append(wav_chunk)

full_audio = np.concatenate(all_chunks)
sf.write(buffer, full_audio, sample_rate, format='WAV', subtype='PCM_16')
```

---

## æ€§èƒ½ä¼˜åŒ–

### å»¶è¿Ÿä¼˜åŒ–

| ä¼˜åŒ–é¡¹ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|--------|--------|--------|------|
| é¦–å­—èŠ‚å»¶è¿Ÿ | 0.250s | 0.001s | 250x |
| æ€»ç”Ÿæˆæ—¶é—´ | 13.90s | 7.87s | 43% |

### ä¼˜åŒ–æªæ–½

1. **ä½¿ç”¨ PCM æ ¼å¼**ï¼šæ— éœ€ç­‰å¾…å®Œæ•´æ•°æ®
2. **å‡å°‘åˆå§‹ç¼“å†²**ï¼šä» 500ms å‡åˆ° 150ms
3. **å¹¶è¡Œå¤„ç†**ï¼šæ¨¡å‹ç”Ÿæˆå’Œç½‘ç»œä¼ è¾“å¹¶è¡Œ

### ç¼“å†²ç­–ç•¥

```
ç¼“å†²å¤ªå° â†’ æ’­æ”¾å¡é¡¿ã€æ‚éŸ³
ç¼“å†²å¤ªå¤§ â†’ å»¶è¿Ÿå¢åŠ 

æ¨èå€¼ï¼š
- åˆå§‹ç¼“å†²ï¼š150msï¼ˆé¦–æ¬¡æ’­æ”¾å‰ç­‰å¾…ï¼‰
- ç´¯ç§¯ç¼“å†²ï¼š500msï¼ˆæ¯æ¬¡æ’­æ”¾çš„æ•°æ®é‡ï¼‰
```

---

## ç»éªŒæ€»ç»“

### âœ… æœ€ä½³å®è·µ

1. **æµå¼ä¼ è¾“ç”¨ PCM**ï¼šWAV/MP3 ç­‰æ ¼å¼éœ€è¦å®Œæ•´æ•°æ®
2. **åç«¯å¤„ç† DC offset**ï¼šä½¿ç”¨æ»‘åŠ¨å¹³å‡ï¼Œä¿æŒ chunk é—´è¿ç»­æ€§
3. **å‰ç«¯å¤„ç†å­—èŠ‚å¯¹é½**ï¼šInt16 å¿…é¡» 2 å­—èŠ‚å¯¹é½
4. **æ·¡å…¥æ•ˆæœåŒä¿é™©**ï¼šåç«¯å’Œå‰ç«¯éƒ½åŠ æ·¡å…¥
5. **ç´¯ç§¯è¶³å¤Ÿæ•°æ®å†æ’­æ”¾**ï¼šå‡å°‘ buffer åˆ‡æ¢å¸¦æ¥çš„æ‚éŸ³
6. **è·Ÿè¸ªæ’­æ”¾çŠ¶æ€**ï¼šé˜²æ­¢éŸ³é¢‘é‡å 

### âŒ å¸¸è§é”™è¯¯

1. **æ¯ä¸ª chunk å•ç‹¬å†™ WAV å¤´**ï¼šå¯¼è‡´å¤§å°ä¸åŒ¹é…
2. **æ¯ä¸ª chunk å•ç‹¬å» DC offset**ï¼šå¯¼è‡´ chunk é—´è·³å˜
3. **ä¸å¤„ç†å­—èŠ‚å¯¹é½**ï¼šå¯¼è‡´ä¸­é—´æ‚éŸ³
4. **ç¼“å†²å¤ªå°**ï¼šå¯¼è‡´æ’­æ”¾å¡é¡¿
5. **ä¸åœæ­¢ä¹‹å‰çš„æ’­æ”¾**ï¼šå¯¼è‡´å£°éŸ³é‡å 

### ğŸ”§ è°ƒè¯•æŠ€å·§

```bash
# åˆ†æ PCM æ–‡ä»¶
python3 -c "
import numpy as np
with open('audio.pcm', 'rb') as f:
    data = f.read()
samples = np.frombuffer(data, dtype=np.int16)
print(f'é‡‡æ ·æ•°: {len(samples)}')
print(f'æ—¶é•¿: {len(samples)/44100:.2f}s')
print(f'DC offset: {samples.mean():.1f}')
print(f'å¼€å¤´10é‡‡æ ·: {samples[:10].tolist()}')
"

# PCM è½¬ WAV
ffmpeg -f s16le -ar 44100 -ac 1 -i audio.pcm audio.wav

# ç›´æ¥æ’­æ”¾ PCM
ffplay -f s16le -ar 44100 -ac 1 -autoexit -nodisp audio.pcm
```

### ğŸ“Š æ€§èƒ½æŒ‡æ ‡å‚è€ƒ

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | è¯´æ˜ |
|------|--------|------|
| é¦–å­—èŠ‚å»¶è¿Ÿ | < 100ms | PCM æ ¼å¼å¯è¾¾ ~1ms |
| æ’­æ”¾å»¶è¿Ÿ | < 200ms | ä»é¦–å­—èŠ‚åˆ°å¼€å§‹æ’­æ”¾ |
| éŸ³é¢‘è´¨é‡ | æ— æ‚éŸ³ | å¼€å¤´æ— çˆ†éŸ³ï¼Œä¸­é—´æ— å™ªå£° |
| CPU å ç”¨ | < 10% | å‰ç«¯è§£ç å’Œæ’­æ”¾ |

---

## å‚è€ƒèµ„æ–™

- [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
- [WAV æ–‡ä»¶æ ¼å¼](http://soundfile.sapp.org/doc/WaveFormat/)
- [PCM éŸ³é¢‘æ ¼å¼](https://en.wikipedia.org/wiki/Pulse-code_modulation)
- [FastAPI StreamingResponse](https://fastapi.tiangolo.com/advanced/custom-response/#streamingresponse)

---

*æœ¬æ–‡æ¡£åŸºäº VoxCPM é¡¹ç›®çš„å®é™…å¼€å‘ç»éªŒæ•´ç†ï¼ŒæŒç»­æ›´æ–°ä¸­ã€‚*
