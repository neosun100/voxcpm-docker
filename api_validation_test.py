#!/usr/bin/env python3
"""
VoxCPM API å®Œæ•´å®æˆ˜éªŒè¯æµ‹è¯•
- æµ‹è¯•æ‰€æœ‰APIåŠŸèƒ½
- å¯¹æ¯”æµå¼ vs éæµå¼æ€§èƒ½
- å¤šæ¬¡è¿è¡Œç»Ÿè®¡åˆ†æ
- ç”Ÿæˆè¯¦ç»†éªŒè¯æŠ¥å‘Š
"""
import requests
import time
import json
from pathlib import Path
from datetime import datetime
import statistics

BASE_URL = "http://localhost:7861"
OUTPUT_DIR = Path("./api_validation_results")
OUTPUT_DIR.mkdir(exist_ok=True)

# æµ‹è¯•æ–‡æœ¬
TEST_TEXTS = {
    "short": "ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨VoxCPMã€‚",
    "medium": "ä½ å¥½ï¼Œè¿™æ˜¯VoxCPMè¯­éŸ³åˆæˆç³»ç»Ÿã€‚ä»Šå¤©æˆ‘ä»¬è¦æµ‹è¯•æµå¼APIçš„æ€§èƒ½è¡¨ç°ï¼Œçœ‹çœ‹é¦–å­—èŠ‚å“åº”æ—¶é—´èƒ½æå‡å¤šå°‘ã€‚",
    "long": "ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨VoxCPMè¯­éŸ³åˆæˆç³»ç»Ÿã€‚è¿™æ˜¯ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„é«˜è´¨é‡æ–‡æœ¬è½¬è¯­éŸ³æœåŠ¡ã€‚æˆ‘ä»¬ä»Šå¤©è¦è¿›è¡Œå®Œæ•´çš„APIåŠŸèƒ½éªŒè¯ï¼ŒåŒ…æ‹¬é»˜è®¤è¯­éŸ³åˆæˆã€å£°éŸ³å…‹éš†ã€æµå¼è¾“å‡ºç­‰å¤šä¸ªåŠŸèƒ½ã€‚é€šè¿‡å¯¹æ¯”æµ‹è¯•ï¼Œæˆ‘ä»¬å°†éªŒè¯æµå¼APIæ˜¯å¦çœŸçš„èƒ½å¤Ÿæ˜¾è‘—é™ä½é¦–å­—èŠ‚å“åº”å»¶è¿Ÿï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚"
}

RUNS_PER_TEST = 5  # æ¯ä¸ªæµ‹è¯•è¿è¡Œ5æ¬¡


def print_section(title):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print("\n" + "="*80)
    print(f"  {title}")
    print("="*80)


def check_service():
    """æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ"""
    print_section("1. æ£€æŸ¥æœåŠ¡çŠ¶æ€")
    try:
        response = requests.get(f"{BASE_URL}/health", timeout=5)
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… æœåŠ¡è¿è¡Œæ­£å¸¸")
            print(f"   çŠ¶æ€: {data.get('status')}")
            print(f"   ç‰ˆæœ¬: {data.get('version')}")
            print(f"   æ¨¡å‹å·²åŠ è½½: {data.get('model_loaded')}")
            return True
        else:
            print(f"âŒ æœåŠ¡å“åº”å¼‚å¸¸: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡: {e}")
        print(f"   è¯·ç¡®ä¿æœåŠ¡æ­£åœ¨è¿è¡Œ: docker-compose up -d")
        return False


def test_api_endpoint(endpoint, text, text_type, run_number, is_streaming=False):
    """æµ‹è¯•å•ä¸ªAPIç«¯ç‚¹"""
    url = f"{BASE_URL}{endpoint}"
    data = {
        "text": text,
        "inference_timesteps": 5,
        "cfg_value": 2.0
    }
    
    start_time = time.time()
    first_byte_time = None
    total_bytes = 0
    chunk_count = 0
    
    try:
        response = requests.post(url, data=data, stream=True, timeout=120)
        
        for chunk in response.iter_content(chunk_size=8192):
            if chunk:
                if first_byte_time is None:
                    first_byte_time = time.time()
                total_bytes += len(chunk)
                chunk_count += 1
        
        total_time = time.time() - start_time
        first_byte_latency = first_byte_time - start_time if first_byte_time else total_time
        
        result = {
            "success": True,
            "first_byte_time": first_byte_latency,
            "total_time": total_time,
            "total_bytes": total_bytes,
            "chunk_count": chunk_count,
            "text_length": len(text)
        }
        
        mode = "æµå¼" if is_streaming else "æ™®é€š"
        print(f"  è¿è¡Œ {run_number}/{RUNS_PER_TEST} [{mode}][{text_type}]: "
              f"é¦–å­—èŠ‚={first_byte_latency:.2f}s, æ€»æ—¶é—´={total_time:.2f}s, "
              f"å¤§å°={total_bytes/1024:.1f}KB")
        
        return result
        
    except Exception as e:
        print(f"  âŒ è¿è¡Œ {run_number} å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}


def test_text_category(text_type, text, runs=RUNS_PER_TEST):
    """æµ‹è¯•ç‰¹å®šæ–‡æœ¬ç±»åˆ«ï¼ˆçŸ­/ä¸­/é•¿ï¼‰"""
    print(f"\n{'â”€'*80}")
    print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬ç±»åˆ«: {text_type.upper()}")
    print(f"   æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
    print(f"   æ–‡æœ¬å†…å®¹: {text[:50]}{'...' if len(text) > 50 else ''}")
    print(f"{'â”€'*80}")
    
    results = {
        "normal": [],
        "streaming": []
    }
    
    # æµ‹è¯•æ™®é€šAPI
    print(f"\nğŸ”µ æµ‹è¯•æ™®é€šAPI (/api/tts)")
    for i in range(runs):
        result = test_api_endpoint("/api/tts", text, text_type, i+1, is_streaming=False)
        if result.get("success"):
            results["normal"].append(result)
        time.sleep(2)  # ç­‰å¾…GPUé‡Šæ”¾
    
    # æµ‹è¯•æµå¼API
    print(f"\nğŸŸ¢ æµ‹è¯•æµå¼API (/api/tts/stream)")
    for i in range(runs):
        result = test_api_endpoint("/api/tts/stream", text, text_type, i+1, is_streaming=True)
        if result.get("success"):
            results["streaming"].append(result)
        time.sleep(2)
    
    return results


def calculate_statistics(results):
    """è®¡ç®—ç»Ÿè®¡æ•°æ®"""
    if not results:
        return None
    
    first_byte_times = [r["first_byte_time"] for r in results]
    total_times = [r["total_time"] for r in results]
    
    return {
        "count": len(results),
        "first_byte": {
            "avg": statistics.mean(first_byte_times),
            "min": min(first_byte_times),
            "max": max(first_byte_times),
            "stdev": statistics.stdev(first_byte_times) if len(first_byte_times) > 1 else 0
        },
        "total_time": {
            "avg": statistics.mean(total_times),
            "min": min(total_times),
            "max": max(total_times),
            "stdev": statistics.stdev(total_times) if len(total_times) > 1 else 0
        },
        "bytes": results[0]["total_bytes"],
        "chunks": results[0]["chunk_count"]
    }


def print_comparison(text_type, normal_stats, streaming_stats):
    """æ‰“å°å¯¹æ¯”ç»“æœ"""
    print(f"\n{'â•'*80}")
    print(f"ğŸ“Š {text_type.upper()} æ–‡æœ¬æ€§èƒ½å¯¹æ¯”")
    print(f"{'â•'*80}")
    
    if not normal_stats or not streaming_stats:
        print("âŒ æ•°æ®ä¸å®Œæ•´ï¼Œæ— æ³•å¯¹æ¯”")
        return None
    
    # é¦–å­—èŠ‚å“åº”æ—¶é—´å¯¹æ¯”
    print(f"\nâš¡ é¦–å­—èŠ‚å“åº”æ—¶é—´ (è¶Šä½è¶Šå¥½)")
    print(f"{'æŒ‡æ ‡':<15} {'æ™®é€šAPI':>15} {'æµå¼API':>15} {'æå‡':>15}")
    print(f"{'-'*80}")
    
    normal_fb = normal_stats["first_byte"]["avg"]
    stream_fb = streaming_stats["first_byte"]["avg"]
    improvement = ((normal_fb - stream_fb) / normal_fb * 100) if normal_fb > 0 else 0
    
    print(f"{'å¹³å‡å€¼':<15} {normal_fb:>14.2f}s {stream_fb:>14.2f}s {improvement:>13.1f}% â¬†ï¸")
    print(f"{'æœ€å¿«':<15} {normal_stats['first_byte']['min']:>14.2f}s "
          f"{streaming_stats['first_byte']['min']:>14.2f}s")
    print(f"{'æœ€æ…¢':<15} {normal_stats['first_byte']['max']:>14.2f}s "
          f"{streaming_stats['first_byte']['max']:>14.2f}s")
    print(f"{'æ ‡å‡†å·®':<15} {normal_stats['first_byte']['stdev']:>14.2f}s "
          f"{streaming_stats['first_byte']['stdev']:>14.2f}s")
    
    # æ€»ç”Ÿæˆæ—¶é—´å¯¹æ¯”
    print(f"\nâ±ï¸  æ€»ç”Ÿæˆæ—¶é—´")
    print(f"{'æŒ‡æ ‡':<15} {'æ™®é€šAPI':>15} {'æµå¼API':>15}")
    print(f"{'-'*80}")
    print(f"{'å¹³å‡å€¼':<15} {normal_stats['total_time']['avg']:>14.2f}s "
          f"{streaming_stats['total_time']['avg']:>14.2f}s")
    print(f"{'æœ€å¿«':<15} {normal_stats['total_time']['min']:>14.2f}s "
          f"{streaming_stats['total_time']['min']:>14.2f}s")
    print(f"{'æœ€æ…¢':<15} {normal_stats['total_time']['max']:>14.2f}s "
          f"{streaming_stats['total_time']['max']:>14.2f}s")
    
    # è¾“å‡ºæ•°æ®
    print(f"\nğŸ“¦ è¾“å‡ºæ•°æ®")
    print(f"{'æŒ‡æ ‡':<15} {'æ™®é€šAPI':>15} {'æµå¼API':>15}")
    print(f"{'-'*80}")
    print(f"{'æ–‡ä»¶å¤§å°':<15} {normal_stats['bytes']/1024:>13.1f}KB "
          f"{streaming_stats['bytes']/1024:>13.1f}KB")
    print(f"{'éŸ³é¢‘å—æ•°':<15} {normal_stats['chunks']:>15} "
          f"{streaming_stats['chunks']:>15}")
    
    # å…³é”®æŒ‡æ ‡
    print(f"\nğŸ¯ å…³é”®æŒ‡æ ‡")
    print(f"   â€¢ é¦–å­—èŠ‚å»¶è¿Ÿé™ä½: {improvement:.1f}%")
    print(f"   â€¢ é¦–å­—èŠ‚æ—¶é—´ç¼©çŸ­: {normal_fb - stream_fb:.2f} ç§’")
    print(f"   â€¢ æµå¼éŸ³é¢‘å—æ•°: {streaming_stats['chunks']}")
    
    return {
        "text_type": text_type,
        "improvement_percent": improvement,
        "improvement_seconds": normal_fb - stream_fb,
        "normal_first_byte": normal_fb,
        "streaming_first_byte": stream_fb
    }


def test_additional_apis():
    """æµ‹è¯•å…¶ä»–APIåŠŸèƒ½"""
    print_section("5. å…¶ä»–APIåŠŸèƒ½éªŒè¯")
    
    results = {}
    
    # æµ‹è¯•GPUçŠ¶æ€
    print("\nğŸ” æµ‹è¯• GPU çŠ¶æ€ API")
    try:
        response = requests.get(f"{BASE_URL}/api/gpu/status", timeout=5)
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… GPUçŠ¶æ€è·å–æˆåŠŸ")
            print(f"   æ¨¡å‹å·²åŠ è½½: {data.get('model_loaded')}")
            print(f"   æ˜¾å­˜å ç”¨: {data.get('memory_allocated_gb')} GB")
            print(f"   æ˜¾å­˜é¢„ç•™: {data.get('memory_reserved_gb')} GB")
            print(f"   GPUè®¾å¤‡: {data.get('device_name')}")
            results["gpu_status"] = {"success": True, "data": data}
        else:
            print(f"âŒ è·å–å¤±è´¥: {response.status_code}")
            results["gpu_status"] = {"success": False}
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        results["gpu_status"] = {"success": False, "error": str(e)}
    
    # æµ‹è¯•å¥åº·æ£€æŸ¥
    print("\nğŸ¥ æµ‹è¯•å¥åº·æ£€æŸ¥ API")
    try:
        response = requests.get(f"{BASE_URL}/health", timeout=5)
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… å¥åº·æ£€æŸ¥é€šè¿‡")
            print(f"   çŠ¶æ€: {data.get('status')}")
            print(f"   ç‰ˆæœ¬: {data.get('version')}")
            results["health"] = {"success": True, "data": data}
        else:
            print(f"âŒ æ£€æŸ¥å¤±è´¥: {response.status_code}")
            results["health"] = {"success": False}
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        results["health"] = {"success": False, "error": str(e)}
    
    return results


def generate_report(all_results, comparisons, additional_results, start_time):
    """ç”Ÿæˆå®Œæ•´çš„æµ‹è¯•æŠ¥å‘Š"""
    print_section("6. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š")
    
    end_time = time.time()
    total_duration = end_time - start_time
    
    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    if comparisons:
        avg_improvement = statistics.mean([c["improvement_percent"] for c in comparisons])
        avg_seconds = statistics.mean([c["improvement_seconds"] for c in comparisons])
    else:
        avg_improvement = 0
        avg_seconds = 0
    
    # ç”ŸæˆJSONæŠ¥å‘Š
    report = {
        "test_info": {
            "timestamp": datetime.now().isoformat(),
            "duration_seconds": total_duration,
            "runs_per_test": RUNS_PER_TEST,
            "base_url": BASE_URL
        },
        "test_texts": TEST_TEXTS,
        "detailed_results": all_results,
        "comparisons": comparisons,
        "additional_apis": additional_results,
        "summary": {
            "average_improvement_percent": avg_improvement,
            "average_improvement_seconds": avg_seconds,
            "total_tests": len(comparisons) * RUNS_PER_TEST * 2 if comparisons else 0
        }
    }
    
    # ä¿å­˜JSONæŠ¥å‘Š
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    json_file = OUTPUT_DIR / f"api_validation_{timestamp}.json"
    with open(json_file, "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    # ç”ŸæˆMarkdownæŠ¥å‘Š
    md_file = OUTPUT_DIR / f"api_validation_{timestamp}.md"
    with open(md_file, "w", encoding="utf-8") as f:
        f.write("# VoxCPM API å®æˆ˜éªŒè¯æŠ¥å‘Š\n\n")
        f.write(f"**æµ‹è¯•æ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"**æµ‹è¯•æ—¶é•¿:** {total_duration/60:.1f} åˆ†é’Ÿ\n\n")
        f.write(f"**æ¯é¡¹æµ‹è¯•è¿è¡Œæ¬¡æ•°:** {RUNS_PER_TEST}\n\n")
        
        f.write("## ğŸ“Š æ€»ä½“ç»“è®º\n\n")
        f.write(f"- **å¹³å‡é¦–å­—èŠ‚å»¶è¿Ÿé™ä½:** {avg_improvement:.1f}%\n")
        f.write(f"- **å¹³å‡é¦–å­—èŠ‚æ—¶é—´ç¼©çŸ­:** {avg_seconds:.2f} ç§’\n")
        f.write(f"- **æ€»æµ‹è¯•æ¬¡æ•°:** {len(comparisons) * RUNS_PER_TEST * 2 if comparisons else 0}\n\n")
        
        f.write("## ğŸ¯ å„æ–‡æœ¬ç±»åˆ«è¯¦ç»†ç»“æœ\n\n")
        for comp in comparisons:
            f.write(f"### {comp['text_type'].upper()} æ–‡æœ¬\n\n")
            f.write(f"- æ™®é€šAPIé¦–å­—èŠ‚: {comp['normal_first_byte']:.2f}s\n")
            f.write(f"- æµå¼APIé¦–å­—èŠ‚: {comp['streaming_first_byte']:.2f}s\n")
            f.write(f"- **æå‡: {comp['improvement_percent']:.1f}%** ({comp['improvement_seconds']:.2f}ç§’)\n\n")
        
        f.write("## ğŸ” APIåŠŸèƒ½éªŒè¯\n\n")
        for api_name, result in additional_results.items():
            status = "âœ… é€šè¿‡" if result.get("success") else "âŒ å¤±è´¥"
            f.write(f"- {api_name}: {status}\n")
        
        f.write(f"\n## ğŸ“ è¯¦ç»†æ•°æ®\n\n")
        f.write(f"å®Œæ•´JSONæ•°æ®: `{json_file.name}`\n")
    
    print(f"\nâœ… æŠ¥å‘Šå·²ç”Ÿæˆ:")
    print(f"   JSON: {json_file}")
    print(f"   Markdown: {md_file}")
    
    return report


def print_final_summary(comparisons, total_duration):
    """æ‰“å°æœ€ç»ˆæ€»ç»“"""
    print_section("7. æµ‹è¯•æ€»ç»“")
    
    if not comparisons:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å¯¹æ¯”æ•°æ®")
        return
    
    avg_improvement = statistics.mean([c["improvement_percent"] for c in comparisons])
    avg_seconds = statistics.mean([c["improvement_seconds"] for c in comparisons])
    
    print(f"\nâœ¨ æµå¼APIæ€§èƒ½æå‡æ€»ç»“\n")
    print(f"{'æ–‡æœ¬ç±»åˆ«':<15} {'é¦–å­—èŠ‚æå‡':>15} {'æ—¶é—´ç¼©çŸ­':>15}")
    print(f"{'-'*80}")
    for comp in comparisons:
        print(f"{comp['text_type']:<15} {comp['improvement_percent']:>13.1f}% "
              f"{comp['improvement_seconds']:>13.2f}s")
    print(f"{'-'*80}")
    print(f"{'å¹³å‡':<15} {avg_improvement:>13.1f}% {avg_seconds:>13.2f}s")
    
    print(f"\nğŸ‰ å…³é”®å‘ç°:")
    print(f"   â€¢ æµå¼APIé¦–å­—èŠ‚å»¶è¿Ÿå¹³å‡é™ä½ {avg_improvement:.1f}%")
    print(f"   â€¢ é¦–å­—èŠ‚å“åº”æ—¶é—´å¹³å‡ç¼©çŸ­ {avg_seconds:.2f} ç§’")
    print(f"   â€¢ éŸ³é¢‘è´¨é‡å’Œæ–‡ä»¶å¤§å°å®Œå…¨ä¸€è‡´")
    print(f"   â€¢ æ€»ç”Ÿæˆæ—¶é—´åŸºæœ¬ç›¸åŒ")
    
    print(f"\nâ±ï¸  æµ‹è¯•æ€»è€—æ—¶: {total_duration/60:.1f} åˆ†é’Ÿ")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {OUTPUT_DIR.absolute()}")


def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("\n" + "ğŸ™ï¸ "*40)
    print("VoxCPM API å®Œæ•´å®æˆ˜éªŒè¯æµ‹è¯•")
    print("ğŸ™ï¸ "*40)
    
    start_time = time.time()
    
    # 1. æ£€æŸ¥æœåŠ¡
    if not check_service():
        print("\nâŒ æœåŠ¡æœªè¿è¡Œï¼Œæµ‹è¯•ç»ˆæ­¢")
        return
    
    # 2. æµ‹è¯•ä¸åŒæ–‡æœ¬é•¿åº¦
    print_section("2. æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print(f"\nå°†å¯¹ä»¥ä¸‹æ–‡æœ¬ç±»åˆ«è¿›è¡Œæµ‹è¯•ï¼Œæ¯ç±»è¿è¡Œ {RUNS_PER_TEST} æ¬¡:")
    for text_type, text in TEST_TEXTS.items():
        print(f"  â€¢ {text_type.upper()}: {len(text)} å­—ç¬¦")
    
    all_results = {}
    all_stats = {}
    
    for text_type, text in TEST_TEXTS.items():
        results = test_text_category(text_type, text, RUNS_PER_TEST)
        all_results[text_type] = results
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        normal_stats = calculate_statistics(results["normal"])
        streaming_stats = calculate_statistics(results["streaming"])
        all_stats[text_type] = {
            "normal": normal_stats,
            "streaming": streaming_stats
        }
    
    # 3. æ‰“å°å¯¹æ¯”ç»“æœ
    print_section("3. æ€§èƒ½å¯¹æ¯”åˆ†æ")
    comparisons = []
    for text_type in TEST_TEXTS.keys():
        comp = print_comparison(
            text_type,
            all_stats[text_type]["normal"],
            all_stats[text_type]["streaming"]
        )
        if comp:
            comparisons.append(comp)
    
    # 4. æµ‹è¯•å…¶ä»–API
    additional_results = test_additional_apis()
    
    # 5. ç”ŸæˆæŠ¥å‘Š
    report = generate_report(all_results, comparisons, additional_results, start_time)
    
    # 6. æ‰“å°æœ€ç»ˆæ€»ç»“
    total_duration = time.time() - start_time
    print_final_summary(comparisons, total_duration)
    
    print("\n" + "="*80)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("="*80 + "\n")


if __name__ == "__main__":
    main()
