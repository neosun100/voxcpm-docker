# VoxCPM Docker é¡¹ç›®ç»“æ„

## ğŸ“ æ–‡ä»¶ç»“æ„

```
VoxCPM/
â”œâ”€â”€ ğŸ³ Docker ç›¸å…³
â”‚   â”œâ”€â”€ Dockerfile              # Docker é•œåƒå®šä¹‰
â”‚   â”œâ”€â”€ docker-compose.yml      # Docker Compose é…ç½®
â”‚   â”œâ”€â”€ .dockerignore          # Docker æ„å»ºå¿½ç•¥æ–‡ä»¶
â”‚   â”œâ”€â”€ .env.example           # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”‚   â””â”€â”€ start.sh               # ä¸€é”®å¯åŠ¨è„šæœ¬ â­
â”‚
â”œâ”€â”€ ğŸš€ æœåŠ¡ç«¯
â”‚   â”œâ”€â”€ server.py              # ç»Ÿä¸€æœåŠ¡å™¨ (UI + API) â­
â”‚   â”œâ”€â”€ mcp_server.py          # MCP æœåŠ¡å™¨ â­
â”‚   â””â”€â”€ gpu_manager.py         # GPU èµ„æºç®¡ç†å™¨ â­
â”‚
â”œâ”€â”€ ğŸ“– æ–‡æ¡£
â”‚   â”œâ”€â”€ QUICKSTART.md          # å¿«é€Ÿå¯åŠ¨æŒ‡å— â­
â”‚   â”œâ”€â”€ README_DOCKER.md       # Docker éƒ¨ç½²æ–‡æ¡£ â­
â”‚   â”œâ”€â”€ MCP_GUIDE.md           # MCP ä½¿ç”¨æŒ‡å— â­
â”‚   â”œâ”€â”€ DOCKER_STRUCTURE.md    # æœ¬æ–‡ä»¶
â”‚   â””â”€â”€ README.md              # é¡¹ç›®ä¸»æ–‡æ¡£
â”‚
â”œâ”€â”€ ğŸ§ª æµ‹è¯•
â”‚   â”œâ”€â”€ test_deployment.sh     # éƒ¨ç½²æµ‹è¯•è„šæœ¬
â”‚   â””â”€â”€ test_mcp.py            # MCP æµ‹è¯•è„šæœ¬
â”‚
â”œâ”€â”€ âš™ï¸ é…ç½®
â”‚   â”œâ”€â”€ mcp_client.json        # MCP å®¢æˆ·ç«¯é…ç½® â­
â”‚   â”œâ”€â”€ Makefile               # å¿«æ·å‘½ä»¤
â”‚   â””â”€â”€ pyproject.toml         # Python é¡¹ç›®é…ç½®
â”‚
â”œâ”€â”€ ğŸ“‚ æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ models/                # æ¨¡å‹æ–‡ä»¶ï¼ˆæŒ‚è½½ï¼‰
â”‚   â”œâ”€â”€ outputs/               # è¾“å‡ºæ–‡ä»¶ï¼ˆæŒ‚è½½ï¼‰
â”‚   â””â”€â”€ examples/              # ç¤ºä¾‹æ–‡ä»¶
â”‚
â””â”€â”€ ğŸ’» æºä»£ç 
    â”œâ”€â”€ src/voxcpm/            # VoxCPM æ ¸å¿ƒä»£ç 
    â”œâ”€â”€ app.py                 # åŸå§‹ Gradio åº”ç”¨
    â””â”€â”€ scripts/               # è®­ç»ƒè„šæœ¬

â­ = Docker åŒ–æ–°å¢æ–‡ä»¶
```

## ğŸ”‘ æ ¸å¿ƒæ–‡ä»¶è¯´æ˜

### 1. server.py
**ç»Ÿä¸€æœåŠ¡å™¨ï¼Œæ•´åˆä¸‰ç§è®¿é—®æ¨¡å¼**

- **UI æ¨¡å¼**: Gradio ç•Œé¢ï¼Œè·¯å¾„ `/`
- **API æ¨¡å¼**: REST APIï¼Œè·¯å¾„ `/api/*`
- **Swagger**: API æ–‡æ¡£ï¼Œè·¯å¾„ `/apidocs`

**ç‰¹ç‚¹**ï¼š
- å•ç«¯å£æœåŠ¡ï¼ˆé»˜è®¤ 7861ï¼‰
- å…±äº« GPU ç®¡ç†å™¨
- è‡ªåŠ¨æ¨¡å‹åŠ è½½/å¸è½½

### 2. mcp_server.py
**MCP åè®®æœåŠ¡å™¨**

æä¾› 4 ä¸ªå·¥å…·ï¼š
- `text_to_speech`: æ–‡æœ¬è½¬è¯­éŸ³
- `voice_cloning`: å£°éŸ³å…‹éš†
- `get_gpu_status`: GPU çŠ¶æ€æŸ¥è¯¢
- `offload_model`: æ¨¡å‹å¸è½½

**ç‰¹ç‚¹**ï¼š
- ç‹¬ç«‹è¿›ç¨‹è¿è¡Œ
- ä¸ API å…±äº« GPU ç®¡ç†é€»è¾‘
- æ”¯æŒç¨‹åºåŒ–è°ƒç”¨

### 3. gpu_manager.py
**GPU èµ„æºç®¡ç†å™¨**

**åŠŸèƒ½**ï¼š
- å»¶è¿ŸåŠ è½½æ¨¡å‹
- è‡ªåŠ¨ç©ºé—²å¸è½½ï¼ˆé»˜è®¤ 60 ç§’ï¼‰
- çº¿ç¨‹å®‰å…¨
- å¼ºåˆ¶å¸è½½æ¥å£

**ä½¿ç”¨**ï¼š
```python
from gpu_manager import gpu_manager

# è·å–æ¨¡å‹ï¼ˆè‡ªåŠ¨åŠ è½½ï¼‰
model = gpu_manager.get_model(load_func)

# å¼ºåˆ¶å¸è½½
gpu_manager.force_offload()
```

### 4. start.sh
**ä¸€é”®å¯åŠ¨è„šæœ¬**

**åŠŸèƒ½**ï¼š
1. æ£€æŸ¥ NVIDIA ç¯å¢ƒ
2. è‡ªåŠ¨é€‰æ‹©æœ€ç©ºé—² GPU
3. æ£€æŸ¥ç«¯å£å¯ç”¨æ€§
4. å¯åŠ¨ Docker Compose
5. æ˜¾ç¤ºè®¿é—®ä¿¡æ¯

**ä½¿ç”¨**ï¼š
```bash
./start.sh
```

## ğŸ”„ æ•°æ®æµ

### UI æ¨¡å¼
```
ç”¨æˆ·æµè§ˆå™¨ â†’ Gradio UI â†’ gpu_manager â†’ VoxCPM æ¨¡å‹ â†’ éŸ³é¢‘è¾“å‡º
```

### API æ¨¡å¼
```
HTTP è¯·æ±‚ â†’ Flask API â†’ gpu_manager â†’ VoxCPM æ¨¡å‹ â†’ éŸ³é¢‘å“åº”
```

### MCP æ¨¡å¼
```
MCP å®¢æˆ·ç«¯ â†’ MCP Server â†’ gpu_manager â†’ VoxCPM æ¨¡å‹ â†’ ç»“æœè¿”å›
```

## ğŸ¯ è®¾è®¡åŸåˆ™

### 1. å•ä¸€ Docker å®¹å™¨
- æ‰€æœ‰æœåŠ¡è¿è¡Œåœ¨åŒä¸€å®¹å™¨
- å…±äº« GPU èµ„æº
- ç»Ÿä¸€ç®¡ç†

### 2. ä¸‰ç§è®¿é—®æ–¹å¼
- **UI**: é€‚åˆäººå·¥äº¤äº’
- **API**: é€‚åˆåº”ç”¨é›†æˆ
- **MCP**: é€‚åˆ AI Agent

### 3. æ™ºèƒ½ GPU ç®¡ç†
- æŒ‰éœ€åŠ è½½
- è‡ªåŠ¨å¸è½½
- æ‰‹åŠ¨æ§åˆ¶

### 4. é›¶é…ç½®å¯åŠ¨
- è‡ªåŠ¨é€‰æ‹© GPU
- è‡ªåŠ¨æ£€æŸ¥ç«¯å£
- ä¸€é”®å¯åŠ¨

## ğŸ“Š ç«¯å£æ˜ å°„

| å®¹å™¨ç«¯å£ | ä¸»æœºç«¯å£ | æœåŠ¡ |
|---------|---------|------|
| 7861 | 7861 | UI + API + Swagger |

## ğŸ’¾ å·æŒ‚è½½

| å®¹å™¨è·¯å¾„ | ä¸»æœºè·¯å¾„ | ç”¨é€” |
|---------|---------|------|
| /app/models | ./models | æ¨¡å‹ç¼“å­˜ |
| /app/outputs | ./outputs | è¾“å‡ºæ–‡ä»¶ |
| /root/.cache/huggingface | ~/.cache/huggingface | HF ç¼“å­˜ |
| /root/.cache/modelscope | ~/.cache/modelscope | MS ç¼“å­˜ |

## ğŸ” ç¯å¢ƒå˜é‡

| å˜é‡ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| PORT | 7861 | æœåŠ¡ç«¯å£ |
| GPU_IDLE_TIMEOUT | 60 | GPU ç©ºé—²è¶…æ—¶ï¼ˆç§’ï¼‰|
| NVIDIA_VISIBLE_DEVICES | 0 | GPU ID |
| HF_REPO_ID | openbmb/VoxCPM1.5 | æ¨¡å‹ ID |

## ğŸš¦ å¯åŠ¨æµç¨‹

```mermaid
graph TD
    A[è¿è¡Œ start.sh] --> B[æ£€æŸ¥ NVIDIA ç¯å¢ƒ]
    B --> C[é€‰æ‹©æœ€ç©ºé—² GPU]
    C --> D[åˆ›å»º/æ›´æ–° .env]
    D --> E[æ£€æŸ¥ç«¯å£å¯ç”¨æ€§]
    E --> F[å¯åŠ¨ Docker Compose]
    F --> G[å®¹å™¨å¯åŠ¨]
    G --> H[åŠ è½½ Python ä¾èµ–]
    H --> I[å¯åŠ¨ server.py]
    I --> J[æœåŠ¡å°±ç»ª]
```

## ğŸ§ª æµ‹è¯•æµç¨‹

```bash
# 1. å¯åŠ¨æœåŠ¡
./start.sh

# 2. è¿è¡Œæµ‹è¯•
./test_deployment.sh

# 3. æµ‹è¯• MCP
./test_mcp.py
```

## ğŸ“ˆ æ€§èƒ½è€ƒè™‘

### GPU å†…å­˜ç®¡ç†
- æ¨¡å‹å¤§å°: ~3GB
- æ¨ç†å³°å€¼: ~5GB
- ç©ºé—²è‡ªåŠ¨é‡Šæ”¾

### å¹¶å‘å¤„ç†
- å• GPU ä¸²è¡Œå¤„ç†
- é˜Ÿåˆ—ç®¡ç†ï¼ˆGradio å†…ç½®ï¼‰
- è¶…æ—¶ä¿æŠ¤

### ç¼“å­˜ç­–ç•¥
- æ¨¡å‹æ–‡ä»¶ç¼“å­˜
- HuggingFace ç¼“å­˜
- ModelScope ç¼“å­˜

## ğŸ”§ è‡ªå®šä¹‰æ‰©å±•

### æ·»åŠ æ–°çš„ API ç«¯ç‚¹
ç¼–è¾‘ `server.py`ï¼š
```python
@app.route('/api/custom', methods=['POST'])
def custom_endpoint():
    # å®ç°é€»è¾‘
    pass
```

### æ·»åŠ æ–°çš„ MCP å·¥å…·
ç¼–è¾‘ `mcp_server.py`ï¼š
```python
@mcp.tool()
def new_tool(param: str) -> dict:
    """å·¥å…·è¯´æ˜"""
    # å®ç°é€»è¾‘
    pass
```

### ä¿®æ”¹ GPU è¶…æ—¶
ä¿®æ”¹ `.env`ï¼š
```bash
GPU_IDLE_TIMEOUT=120  # 2 åˆ†é’Ÿ
```

## ğŸ› è°ƒè¯•æŠ€å·§

### æŸ¥çœ‹å®æ—¶æ—¥å¿—
```bash
docker-compose logs -f
```

### è¿›å…¥å®¹å™¨è°ƒè¯•
```bash
docker exec -it voxcpm-service bash
```

### æ£€æŸ¥ GPU çŠ¶æ€
```bash
# ä¸»æœº
nvidia-smi

# å®¹å™¨å†…
docker exec voxcpm-service nvidia-smi
```

### æµ‹è¯• API
```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:7861/health

# GPU çŠ¶æ€
curl http://localhost:7861/api/gpu/status
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [å¿«é€Ÿå¯åŠ¨](QUICKSTART.md) - 30 ç§’ä¸Šæ‰‹
- [éƒ¨ç½²æŒ‡å—](README_DOCKER.md) - å®Œæ•´éƒ¨ç½²æ–‡æ¡£
- [MCP æŒ‡å—](MCP_GUIDE.md) - MCP ä½¿ç”¨è¯´æ˜
- [é¡¹ç›®ä¸»é¡µ](README.md) - VoxCPM ä»‹ç»
