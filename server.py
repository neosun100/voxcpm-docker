import os
import time
import soundfile as sf
from pathlib import Path
from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
import gradio as gr
import uvicorn
from gpu_manager import gpu_manager
import voxcpm
import torch

PORT = int(os.getenv("PORT", "7861"))
OUTPUT_DIR = Path("/app/outputs")
UPLOAD_DIR = Path("/app/uploads")
OUTPUT_DIR.mkdir(exist_ok=True)
UPLOAD_DIR.mkdir(exist_ok=True)

# Performance optimization
DEFAULT_TIMESTEPS = 5  # Reduced from 10 for 2x speed
FAST_MODE_TIMESTEPS = 3  # Ultra-fast mode

# FastAPI app
app = FastAPI(title="VoxCPM API", version="1.0.1")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

def load_model():
    model_path = os.getenv("HF_REPO_ID", "openbmb/VoxCPM1.5")
    model = voxcpm.VoxCPM.from_pretrained(model_path)
    # Enable torch compile for faster inference
    if hasattr(torch, 'compile') and torch.cuda.is_available():
        try:
            model.tts_model = torch.compile(model.tts_model, mode="reduce-overhead")
        except:
            pass
    return model

@app.get("/health")
def health():
    """Health check endpoint"""
    return {"status": "healthy", "model_loaded": gpu_manager.is_loaded(), "version": "1.0.1"}

@app.post("/api/tts")
async def tts(
    text: str = Form(...),
    prompt_audio: UploadFile = File(None),
    prompt_text: str = Form(None),
    cfg_value: float = Form(2.0),
    inference_timesteps: int = Form(DEFAULT_TIMESTEPS),
    min_len: int = Form(2),
    max_len: int = Form(4096),
    normalize: bool = Form(False),
    denoise: bool = Form(False),
    retry_badcase: bool = Form(False),
    retry_badcase_max_times: int = Form(3),
    retry_badcase_ratio_threshold: float = Form(6.0),
):
    """Text-to-Speech API"""
    try:
        prompt_wav_path = None
        if prompt_audio:
            prompt_wav_path = UPLOAD_DIR / f"prompt_{int(time.time())}_{prompt_audio.filename}"
            with open(prompt_wav_path, "wb") as f:
                f.write(await prompt_audio.read())
        
        model = gpu_manager.get_model(load_model)
        
        wav = model.generate(
            text=text,
            prompt_wav_path=str(prompt_wav_path) if prompt_wav_path else None,
            prompt_text=prompt_text,
            cfg_value=cfg_value,
            inference_timesteps=inference_timesteps,
            min_len=min_len,
            max_len=max_len,
            normalize=normalize,
            denoise=denoise,
            retry_badcase=retry_badcase,
            retry_badcase_max_times=retry_badcase_max_times,
            retry_badcase_ratio_threshold=retry_badcase_ratio_threshold,
        )
        
        output_path = OUTPUT_DIR / f"output_{int(time.time())}.wav"
        sf.write(output_path, wav, model.tts_model.sample_rate)
        
        return FileResponse(output_path, media_type="audio/wav")
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/gpu/offload")
def gpu_offload():
    """Offload model from GPU"""
    gpu_manager.force_offload()
    return {"status": "offloaded"}

@app.get("/api/gpu/status")
def gpu_status():
    """Get GPU status"""
    import torch
    if torch.cuda.is_available():
        return {
            "model_loaded": gpu_manager.is_loaded(),
            "memory_allocated_gb": round(torch.cuda.memory_allocated() / 1024**3, 2),
            "memory_reserved_gb": round(torch.cuda.memory_reserved() / 1024**3, 2),
            "device_name": torch.cuda.get_device_name(0)
        }
    return {"error": "CUDA not available"}

# Gradio UI - Chinese Interface
def create_ui():
    with gr.Blocks(title="VoxCPM è¯­éŸ³åˆæˆ", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # ğŸ™ï¸ VoxCPM æ–‡æœ¬è½¬è¯­éŸ³æœåŠ¡ v1.0.1
        ### é«˜è´¨é‡ç¥ç»ç½‘ç»œè¯­éŸ³åˆæˆï¼Œæ”¯æŒå£°éŸ³å…‹éš† | å·²ä¼˜åŒ–æ€§èƒ½ï¼Œç”Ÿæˆé€Ÿåº¦æå‡ 2-3 å€
        """)
        
        with gr.Tab("ğŸ¤ è¯­éŸ³åˆæˆ"):
            gr.Markdown("""
            ### ğŸ“– ä½¿ç”¨è¯´æ˜
            1. **è¾“å…¥æ–‡æœ¬**ï¼šåœ¨ä¸‹æ–¹æ–‡æœ¬æ¡†è¾“å…¥è¦åˆæˆçš„å†…å®¹ï¼ˆå»ºè®® 100 å­—ä»¥å†…ï¼‰
            2. **é€‰æ‹©é€Ÿåº¦æ¨¡å¼**ï¼šæé€Ÿæ¨¡å¼ï¼ˆ3æ­¥ï¼‰æœ€å¿«ï¼Œæ ‡å‡†æ¨¡å¼ï¼ˆ5æ­¥ï¼‰å¹³è¡¡ï¼Œé«˜è´¨é‡æ¨¡å¼ï¼ˆ10æ­¥ï¼‰æœ€ä½³
            3. **ç‚¹å‡»ç”Ÿæˆ**ï¼šç­‰å¾… 10-30 ç§’å³å¯è·å¾—éŸ³é¢‘
            
            ğŸ’¡ **åŠ é€ŸæŠ€å·§**ï¼š
            - ä½¿ç”¨æé€Ÿæ¨¡å¼å¯æé€Ÿ 3-4 å€ï¼ˆé€‚åˆå¿«é€Ÿæµ‹è¯•ï¼‰
            - æ ‡å‡†æ¨¡å¼æé€Ÿ 2 å€ï¼ˆæ¨èæ—¥å¸¸ä½¿ç”¨ï¼‰
            - æ–‡æœ¬è¶ŠçŸ­ï¼Œç”Ÿæˆè¶Šå¿«
            - å…³é—­"é”™è¯¯é‡è¯•"å¯èŠ‚çœæ—¶é—´
            """)
            
            with gr.Row():
                with gr.Column(scale=2):
                    text_input = gr.Textbox(
                        label="ğŸ“ è¾“å…¥æ–‡æœ¬", 
                        lines=5, 
                        placeholder="åœ¨æ­¤è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬...\n\nç¤ºä¾‹ï¼š\nä½ å¥½ï¼Œæˆ‘æ˜¯ VoxCPM è¯­éŸ³åˆæˆç³»ç»Ÿã€‚\nä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼Œé€‚åˆå‡ºå»èµ°èµ°ã€‚"
                    )
                    gr.Markdown("ğŸ’¡ **æç¤º**: å»ºè®®è¾“å…¥ 100 å­—ä»¥å†…çš„æ–‡æœ¬ï¼Œç”Ÿæˆé€Ÿåº¦æ›´å¿«")
                    
                    speed_mode = gr.Radio(
                        choices=["ğŸš€ æé€Ÿæ¨¡å¼ (3æ­¥, ~10ç§’)", "âš¡ æ ‡å‡†æ¨¡å¼ (5æ­¥, ~15ç§’)", "ğŸ¯ é«˜è´¨é‡æ¨¡å¼ (10æ­¥, ~30ç§’)"],
                        value="âš¡ æ ‡å‡†æ¨¡å¼ (5æ­¥, ~15ç§’)",
                        label="é€Ÿåº¦æ¨¡å¼"
                    )
                    gr.Markdown("ğŸ’¡ **æç¤º**: æé€Ÿæ¨¡å¼æœ€å¿«ä½†è´¨é‡ç•¥ä½ï¼Œæ ‡å‡†æ¨¡å¼å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡ï¼ˆæ¨èï¼‰")
                
                with gr.Column(scale=1):
                    gr.Markdown("""
                    ### âš™ï¸ é«˜çº§å‚æ•°
                    """)
                    cfg_value = gr.Slider(
                        1.0, 5.0, value=2.0, step=0.1, 
                        label="CFG å¼•å¯¼å¼ºåº¦"
                    )
                    gr.Markdown("ğŸ’¡ è¶Šé«˜è¶Šç¨³å®šï¼Œä½†å¯èƒ½é™ä½è‡ªç„¶åº¦")
                    normalize = gr.Checkbox(
                        label="æ–‡æœ¬è§„èŒƒåŒ–", 
                        value=False
                    )
                    gr.Markdown("ğŸ’¡ è‡ªåŠ¨å¤„ç†æ•°å­—ã€ç¬¦å·ç­‰")
                    denoise = gr.Checkbox(
                        label="éŸ³é¢‘é™å™ª", 
                        value=False
                    )
                    gr.Markdown("ğŸ’¡ å¯èƒ½å¢åŠ å¤„ç†æ—¶é—´")
                    retry_badcase = gr.Checkbox(
                        label="é”™è¯¯è‡ªåŠ¨é‡è¯•", 
                        value=False
                    )
                    gr.Markdown("ğŸ’¡ å…³é—­å¯åŠ å¿«é€Ÿåº¦")
                    
                    synthesize_btn = gr.Button("ğŸµ å¼€å§‹ç”Ÿæˆè¯­éŸ³", variant="primary", size="lg")
            
            audio_output = gr.Audio(label="ğŸ”Š ç”Ÿæˆçš„éŸ³é¢‘")
            
            gr.Markdown("""
            ---
            ### ğŸ“Š æ€§èƒ½å¯¹æ¯”
            | æ¨¡å¼ | æ¨ç†æ­¥æ•° | é¢„è®¡æ—¶é—´ | è´¨é‡ | é€‚ç”¨åœºæ™¯ |
            |------|---------|---------|------|---------|
            | ğŸš€ æé€Ÿ | 3 æ­¥ | ~10 ç§’ | â­â­â­ | å¿«é€Ÿæµ‹è¯•ã€é¢„è§ˆ |
            | âš¡ æ ‡å‡† | 5 æ­¥ | ~15 ç§’ | â­â­â­â­ | æ—¥å¸¸ä½¿ç”¨ï¼ˆæ¨èï¼‰|
            | ğŸ¯ é«˜è´¨é‡ | 10 æ­¥ | ~30 ç§’ | â­â­â­â­â­ | æ­£å¼å‘å¸ƒã€é«˜è¦æ±‚ |
            """)
        
        with gr.Tab("ğŸ­ å£°éŸ³å…‹éš†"):
            gr.Markdown("""
            ### ğŸ“– ä½¿ç”¨è¯´æ˜
            1. **ä¸Šä¼ å‚è€ƒéŸ³é¢‘**ï¼šé€‰æ‹©ä¸€æ®µ 3-10 ç§’çš„æ¸…æ™°äººå£°ï¼ˆæ”¯æŒ WAV/MP3ï¼‰
            2. **è¾“å…¥å‚è€ƒæ–‡æœ¬**ï¼ˆå¯é€‰ï¼‰ï¼šå‚è€ƒéŸ³é¢‘å¯¹åº”çš„æ–‡å­—å†…å®¹ï¼Œå¯æé«˜å…‹éš†è´¨é‡
            3. **è¾“å…¥ç›®æ ‡æ–‡æœ¬**ï¼šè¦ç”¨å…‹éš†å£°éŸ³è¯´çš„å†…å®¹
            4. **é€‰æ‹©é€Ÿåº¦æ¨¡å¼**ï¼šåŒè¯­éŸ³åˆæˆ
            5. **ç‚¹å‡»å…‹éš†**ï¼šç­‰å¾…ç”Ÿæˆ
            
            ğŸ’¡ **å…‹éš†æŠ€å·§**ï¼š
            - å‚è€ƒéŸ³é¢‘è¦æ¸…æ™°ã€æ— èƒŒæ™¯å™ªéŸ³
            - éŸ³é¢‘æ—¶é•¿ 3-10 ç§’æœ€ä½³
            - æä¾›å‚è€ƒæ–‡æœ¬å¯æé«˜è´¨é‡
            - ç›®æ ‡æ–‡æœ¬ä¸å®œè¿‡é•¿ï¼ˆ100 å­—ä»¥å†…ï¼‰
            """)
            
            with gr.Row():
                with gr.Column(scale=2):
                    clone_text = gr.Textbox(
                        label="ğŸ“ ç›®æ ‡æ–‡æœ¬", 
                        lines=4, 
                        placeholder="è¾“å…¥è¦ç”¨å…‹éš†å£°éŸ³è¯´çš„å†…å®¹..."
                    )
                    gr.Markdown("ğŸ’¡ å»ºè®® 100 å­—ä»¥å†…")
                    prompt_audio = gr.Audio(
                        label="ğŸ¤ å‚è€ƒéŸ³é¢‘", 
                        type="filepath"
                    )
                    gr.Markdown("ğŸ’¡ ä¸Šä¼  3-10 ç§’çš„æ¸…æ™°äººå£°")
                    prompt_text = gr.Textbox(
                        label="ğŸ“„ å‚è€ƒæ–‡æœ¬ï¼ˆå¯é€‰ï¼‰", 
                        lines=2, 
                        placeholder="å‚è€ƒéŸ³é¢‘å¯¹åº”çš„æ–‡å­—å†…å®¹..."
                    )
                    gr.Markdown("ğŸ’¡ æä¾›å‚è€ƒæ–‡æœ¬å¯æé«˜å…‹éš†è´¨é‡")
                    
                    clone_speed_mode = gr.Radio(
                        choices=["ğŸš€ æé€Ÿæ¨¡å¼ (3æ­¥)", "âš¡ æ ‡å‡†æ¨¡å¼ (5æ­¥)", "ğŸ¯ é«˜è´¨é‡æ¨¡å¼ (10æ­¥)"],
                        value="âš¡ æ ‡å‡†æ¨¡å¼ (5æ­¥)",
                        label="é€Ÿåº¦æ¨¡å¼"
                    )
                
                with gr.Column(scale=1):
                    gr.Markdown("### âš™ï¸ é«˜çº§å‚æ•°")
                    clone_cfg = gr.Slider(1.0, 5.0, value=2.0, step=0.1, label="CFG å¼•å¯¼å¼ºåº¦")
                    clone_normalize = gr.Checkbox(label="æ–‡æœ¬è§„èŒƒåŒ–", value=False)
                    clone_denoise = gr.Checkbox(label="éŸ³é¢‘é™å™ª", value=False)
                    clone_retry = gr.Checkbox(label="é”™è¯¯è‡ªåŠ¨é‡è¯•", value=False)
                    
                    clone_btn = gr.Button("ğŸ­ å¼€å§‹å…‹éš†å£°éŸ³", variant="primary", size="lg")
            
            clone_output = gr.Audio(label="ğŸ”Š å…‹éš†çš„éŸ³é¢‘")
        
        with gr.Tab("ğŸ–¥ï¸ GPU çŠ¶æ€"):
            gr.Markdown("""
            ### ğŸ’» ç³»ç»ŸçŠ¶æ€ç›‘æ§
            æŸ¥çœ‹ GPU ä½¿ç”¨æƒ…å†µå’Œæ¨¡å‹åŠ è½½çŠ¶æ€
            """)
            gpu_info = gr.Textbox(label="GPU çŠ¶æ€", lines=6, interactive=False)
            with gr.Row():
                refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°çŠ¶æ€", size="lg")
                offload_btn = gr.Button("ğŸ—‘ï¸ å¸è½½æ¨¡å‹ï¼ˆé‡Šæ”¾æ˜¾å­˜ï¼‰", size="lg", variant="stop")
            
            gr.Markdown("""
            ---
            ### ğŸ“Œ è¯´æ˜
            - **æ¨¡å‹å·²åŠ è½½**ï¼šæ¨¡å‹åœ¨ GPU ä¸Šï¼Œå¯ç›´æ¥ç”Ÿæˆ
            - **æ¨¡å‹æœªåŠ è½½**ï¼šé¦–æ¬¡ç”Ÿæˆæ—¶ä¼šè‡ªåŠ¨åŠ è½½ï¼ˆçº¦ 15 ç§’ï¼‰
            - **å¸è½½æ¨¡å‹**ï¼šé‡Šæ”¾ GPU æ˜¾å­˜ï¼Œä¸‹æ¬¡ä½¿ç”¨æ—¶ä¼šé‡æ–°åŠ è½½
            - **ç©ºé—²è¶…æ—¶**ï¼šæ¨¡å‹é—²ç½® 60 ç§’åè‡ªåŠ¨å¸è½½
            """)
        
        with gr.Tab("â“ å¸®åŠ©"):
            gr.Markdown("""
            # ğŸ“š VoxCPM ä½¿ç”¨æŒ‡å—
            
            ## ğŸš€ å¿«é€Ÿå¼€å§‹
            
            ### è¯­éŸ³åˆæˆï¼ˆæœ€ç®€å•ï¼‰
            1. åˆ‡æ¢åˆ°"è¯­éŸ³åˆæˆ"æ ‡ç­¾
            2. è¾“å…¥æ–‡æœ¬ï¼ˆå¦‚ï¼š"ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨ VoxCPM"ï¼‰
            3. é€‰æ‹©"æ ‡å‡†æ¨¡å¼"
            4. ç‚¹å‡»"å¼€å§‹ç”Ÿæˆè¯­éŸ³"
            5. ç­‰å¾… 15 ç§’å·¦å³å³å¯è·å¾—éŸ³é¢‘
            
            ### å£°éŸ³å…‹éš†ï¼ˆè¿›é˜¶ï¼‰
            1. å‡†å¤‡ä¸€æ®µ 3-10 ç§’çš„æ¸…æ™°äººå£°å½•éŸ³
            2. åˆ‡æ¢åˆ°"å£°éŸ³å…‹éš†"æ ‡ç­¾
            3. ä¸Šä¼ å‚è€ƒéŸ³é¢‘
            4. è¾“å…¥ç›®æ ‡æ–‡æœ¬
            5. ç‚¹å‡»"å¼€å§‹å…‹éš†å£°éŸ³"
            
            ## âš¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®
            
            ### å¦‚ä½•åŠ å¿«ç”Ÿæˆé€Ÿåº¦ï¼Ÿ
            1. **ä½¿ç”¨æé€Ÿæ¨¡å¼**ï¼š3 æ­¥æ¨ç†ï¼Œé€Ÿåº¦æœ€å¿«ï¼ˆ~10 ç§’ï¼‰
            2. **ä½¿ç”¨æ ‡å‡†æ¨¡å¼**ï¼š5 æ­¥æ¨ç†ï¼Œå¹³è¡¡é€Ÿåº¦å’Œè´¨é‡ï¼ˆ~15 ç§’ï¼Œæ¨èï¼‰
            3. **ç¼©çŸ­æ–‡æœ¬é•¿åº¦**ï¼š100 å­—ä»¥å†…ç”Ÿæˆæœ€å¿«
            4. **å…³é—­é”™è¯¯é‡è¯•**ï¼šå¯èŠ‚çœ 20-30% æ—¶é—´
            5. **å…³é—­é™å™ª**ï¼šå¯èŠ‚çœ 10-15% æ—¶é—´
            
            ### ä¸ºä»€ä¹ˆç¬¬ä¸€æ¬¡ç”Ÿæˆå¾ˆæ…¢ï¼Ÿ
            - é¦–æ¬¡ç”Ÿæˆéœ€è¦åŠ è½½æ¨¡å‹åˆ° GPUï¼ˆçº¦ 15 ç§’ï¼‰
            - åç»­ç”Ÿæˆä¼šå¿«å¾ˆå¤šï¼ˆ10-30 ç§’ï¼‰
            - æ¨¡å‹ä¼šåœ¨é—²ç½® 60 ç§’åè‡ªåŠ¨å¸è½½
            
            ### å„æ¨¡å¼å¯¹æ¯”
            | æ¨¡å¼ | é€Ÿåº¦ | è´¨é‡ | æ¨èåœºæ™¯ |
            |------|------|------|---------|
            | æé€Ÿ | â­â­â­â­â­ | â­â­â­ | å¿«é€Ÿæµ‹è¯•ã€é¢„è§ˆ |
            | æ ‡å‡† | â­â­â­â­ | â­â­â­â­ | æ—¥å¸¸ä½¿ç”¨ |
            | é«˜è´¨é‡ | â­â­â­ | â­â­â­â­â­ | æ­£å¼å‘å¸ƒ |
            
            ## ğŸ”§ å¸¸è§é—®é¢˜
            
            ### Q: ç”Ÿæˆå¤±è´¥æ€ä¹ˆåŠï¼Ÿ
            A: 
            1. æ£€æŸ¥æ–‡æœ¬æ˜¯å¦è¿‡é•¿ï¼ˆå»ºè®® 100 å­—ä»¥å†…ï¼‰
            2. å°è¯•å¼€å¯"é”™è¯¯è‡ªåŠ¨é‡è¯•"
            3. æ£€æŸ¥ GPU çŠ¶æ€æ˜¯å¦æ­£å¸¸
            4. åˆ·æ–°é¡µé¢é‡è¯•
            
            ### Q: éŸ³è´¨ä¸å¥½æ€ä¹ˆåŠï¼Ÿ
            A:
            1. ä½¿ç”¨"é«˜è´¨é‡æ¨¡å¼"ï¼ˆ10 æ­¥ï¼‰
            2. é€‚å½“æé«˜ CFG å€¼ï¼ˆ2.5-3.0ï¼‰
            3. å¼€å¯"æ–‡æœ¬è§„èŒƒåŒ–"
            4. å¯¹äºå£°éŸ³å…‹éš†ï¼Œä½¿ç”¨æ›´æ¸…æ™°çš„å‚è€ƒéŸ³é¢‘
            
            ### Q: å¦‚ä½•è·å¾—æœ€ä½³æ•ˆæœï¼Ÿ
            A:
            1. æ–‡æœ¬ï¼šç®€æ´æ¸…æ™°ï¼Œæ ‡ç‚¹æ­£ç¡®
            2. å‚è€ƒéŸ³é¢‘ï¼š3-10 ç§’ï¼Œæ¸…æ™°æ— å™ªéŸ³
            3. å‚æ•°ï¼šæ ‡å‡†æ¨¡å¼ + CFG 2.0
            4. æä¾›å‚è€ƒæ–‡æœ¬ï¼ˆå£°éŸ³å…‹éš†æ—¶ï¼‰
            
            ## ğŸ“Š æŠ€æœ¯å‚æ•°è¯´æ˜
            
            ### CFG å¼•å¯¼å¼ºåº¦ (1.0-5.0)
            - **ä½å€¼ (1.0-1.5)**ï¼šæ›´è‡ªç„¶ï¼Œä½†å¯èƒ½ä¸ç¨³å®š
            - **ä¸­å€¼ (2.0-2.5)**ï¼šå¹³è¡¡è‡ªç„¶åº¦å’Œç¨³å®šæ€§ï¼ˆæ¨èï¼‰
            - **é«˜å€¼ (3.0-5.0)**ï¼šæ›´ç¨³å®šï¼Œä½†å¯èƒ½ä¸å¤Ÿè‡ªç„¶
            
            ### æ¨ç†æ­¥æ•°
            - **3 æ­¥**ï¼šæé€Ÿï¼Œè´¨é‡ç•¥ä½
            - **5 æ­¥**ï¼šæ ‡å‡†ï¼Œå¹³è¡¡é€Ÿåº¦å’Œè´¨é‡
            - **10 æ­¥**ï¼šé«˜è´¨é‡ï¼Œé€Ÿåº¦è¾ƒæ…¢
            - **20 æ­¥**ï¼šæœ€é«˜è´¨é‡ï¼Œé€Ÿåº¦æœ€æ…¢ï¼ˆä¸æ¨èæ—¥å¸¸ä½¿ç”¨ï¼‰
            
            ## ğŸŒ API ä½¿ç”¨
            
            ### REST API ç«¯ç‚¹
            - **å¥åº·æ£€æŸ¥**: `GET /health`
            - **è¯­éŸ³åˆæˆ**: `POST /api/tts`
            - **GPU çŠ¶æ€**: `GET /api/gpu/status`
            - **GPU å¸è½½**: `POST /api/gpu/offload`
            - **API æ–‡æ¡£**: `/docs`
            
            ### ç¤ºä¾‹ï¼ˆcurlï¼‰
            ```bash
            curl -X POST http://localhost:7861/api/tts \\
              -F "text=ä½ å¥½ï¼Œæˆ‘æ˜¯ VoxCPM" \\
              -F "inference_timesteps=5" \\
              -o output.wav
            ```
            
            ## ğŸ“ è”ç³»æ”¯æŒ
            - GitHub: https://github.com/neosun100/voxcpm-docker
            - Docker Hub: https://hub.docker.com/r/neosun/voxcpm-allinone
            - åœ¨çº¿æ¼”ç¤º: https://voxcpm-tts.aws.xin
            
            ---
            **ç‰ˆæœ¬**: v1.0.1 | **æ›´æ–°æ—¥æœŸ**: 2025-12-12
            """)
        
        # Functions
        def get_steps_from_mode(mode):
            if "æé€Ÿ" in mode:
                return FAST_MODE_TIMESTEPS
            elif "æ ‡å‡†" in mode:
                return DEFAULT_TIMESTEPS
            else:
                return 10
        
        def synthesize(text, mode, cfg, norm, den, retry):
            if not text.strip():
                return None
            steps = get_steps_from_mode(mode)
            model = gpu_manager.get_model(load_model)
            wav = model.generate(
                text=text, 
                cfg_value=cfg, 
                inference_timesteps=steps,
                normalize=norm, 
                denoise=den,
                retry_badcase=retry
            )
            path = OUTPUT_DIR / f"synth_{int(time.time())}.wav"
            sf.write(path, wav, model.tts_model.sample_rate)
            return str(path)
        
        def clone_voice(text, audio, transcript, mode, cfg, norm, den, retry):
            if not text.strip() or not audio:
                return None
            steps = get_steps_from_mode(mode)
            model = gpu_manager.get_model(load_model)
            wav = model.generate(
                text=text, 
                prompt_wav_path=audio, 
                prompt_text=transcript if transcript else None,
                cfg_value=cfg, 
                inference_timesteps=steps,
                normalize=norm,
                denoise=den,
                retry_badcase=retry
            )
            path = OUTPUT_DIR / f"clone_{int(time.time())}.wav"
            sf.write(path, wav, model.tts_model.sample_rate)
            return str(path)
        
        def get_gpu_status():
            import torch
            if torch.cuda.is_available():
                return f"""æ¨¡å‹çŠ¶æ€: {'âœ… å·²åŠ è½½' if gpu_manager.is_loaded() else 'âŒ æœªåŠ è½½'}
GPU è®¾å¤‡: {torch.cuda.get_device_name(0)}
æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated()/1024**3:.2f} GB
æ˜¾å­˜é¢„ç•™: {torch.cuda.memory_reserved()/1024**3:.2f} GB
ç‰ˆæœ¬: v1.0.1"""
            return "CUDA ä¸å¯ç”¨"
        
        def offload_model():
            gpu_manager.force_offload()
            return "âœ… æ¨¡å‹å·²å¸è½½ï¼Œæ˜¾å­˜å·²é‡Šæ”¾"
        
        # Event bindings
        synthesize_btn.click(
            synthesize,
            inputs=[text_input, speed_mode, cfg_value, normalize, denoise, retry_badcase],
            outputs=audio_output
        )
        
        clone_btn.click(
            clone_voice,
            inputs=[clone_text, prompt_audio, prompt_text, clone_speed_mode, 
                   clone_cfg, clone_normalize, clone_denoise, clone_retry],
            outputs=clone_output
        )
        
        refresh_btn.click(get_gpu_status, outputs=gpu_info)
        offload_btn.click(offload_model, outputs=gpu_info)
        demo.load(get_gpu_status, outputs=gpu_info)
    
    return demo

# Mount Gradio app
demo = create_ui()
app = gr.mount_gradio_app(app, demo, path="/")

if __name__ == "__main__":
    print("ğŸš€ Starting VoxCPM Server on 0.0.0.0:{}".format(PORT))
    print("ğŸ“ UI:      http://0.0.0.0:{}".format(PORT))
    print("ğŸ“ API:     http://0.0.0.0:{}/api".format(PORT))
    print("ğŸ“ Docs:    http://0.0.0.0:{}/docs".format(PORT))
    print("ğŸ“ Health:  http://0.0.0.0:{}/health".format(PORT))
    uvicorn.run(app, host="0.0.0.0", port=PORT)
